# Model-specific configuration for AQI Predictor

# Sklearn Models Configuration
sklearn_models:
  random_forest:
    n_estimators: 200
    max_depth: 15
    min_samples_split: 5
    min_samples_leaf: 2
    max_features: "sqrt"
    random_state: 42
    n_jobs: -1
  
  ridge:
    alpha: 1.0
    solver: "auto"
  
  gradient_boosting:
    n_estimators: 200
    learning_rate: 0.1
    max_depth: 5
    min_samples_split: 5
    min_samples_leaf: 2
    random_state: 42
  
  elastic_net:
    alpha: 1.0
    l1_ratio: 0.5
    max_iter: 1000
    random_state: 42

# Deep Learning Models Configuration
deep_learning_models:
  mlp:
    hidden_layers: [128, 64, 32]
    activation: "relu"
    dropout_rate: 0.3
    learning_rate: 0.001
    batch_normalization: true
  
  lstm:
    units: [64, 32]
    dropout_rate: 0.2
    recurrent_dropout: 0.2
    learning_rate: 0.001
    bidirectional: false
  
  gru:
    units: [64, 32]
    dropout_rate: 0.2
    recurrent_dropout: 0.2
    learning_rate: 0.001
  
  cnn_lstm:
    conv_filters: [32, 64]
    kernel_size: 3
    pool_size: 2
    lstm_units: 32
    dropout_rate: 0.2
    learning_rate: 0.001

# Training Parameters
training:
  optimizer: "adam"
  loss: "mse"
  metrics:
    - mae
  callbacks:
    early_stopping:
      monitor: "val_loss"
      patience: 10
      restore_best_weights: true
    reduce_lr:
      monitor: "val_loss"
      factor: 0.5
      patience: 5
      min_lr: 0.0001
    model_checkpoint:
      monitor: "val_loss"
      save_best_only: true

# Hyperparameter Tuning
hyperparameter_tuning:
  enabled: false
  method: "bayesian"  # Options: grid, random, bayesian
  cv_folds: 5
  n_trials: 50
  
  search_spaces:
    random_forest:
      n_estimators: [100, 200, 300, 500]
      max_depth: [5, 10, 15, 20, null]
      min_samples_split: [2, 5, 10]
    
    gradient_boosting:
      n_estimators: [100, 200, 300]
      learning_rate: [0.01, 0.05, 0.1, 0.2]
      max_depth: [3, 5, 7, 10]
    
    lstm:
      units: [[32], [64], [64, 32], [128, 64]]
      dropout_rate: [0.1, 0.2, 0.3]
      learning_rate: [0.0001, 0.001, 0.01]

# Ensemble Configuration
ensemble:
  enabled: false
  method: "stacking"  # Options: stacking, voting, blending
  base_models:
    - random_forest
    - gradient_boosting
    - lstm
  meta_model: "ridge"
  cv_folds: 5
