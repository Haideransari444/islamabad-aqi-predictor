{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec4f1d96",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15d6ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "# !pip install requests pandas python-dotenv matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "233e4372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfeb19ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìç Location: Islamabad, Pakistan\n",
      "üìç Coordinates: Lat=33.6844, Lon=73.0479\n",
      "üîë API Key configured: Yes ‚úÖ\n",
      "üîë API Key (masked): 91bd932c...a08d\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv('../.env')\n",
    "\n",
    "# Configuration\n",
    "API_KEY = os.getenv('OPENWEATHER_API_KEY', 'your_api_key_here')\n",
    "\n",
    "# Islamabad, Pakistan coordinates\n",
    "LAT = 33.6844\n",
    "LON = 73.0479\n",
    "\n",
    "print(f\"üìç Location: Islamabad, Pakistan\")\n",
    "print(f\"üìç Coordinates: Lat={LAT}, Lon={LON}\")\n",
    "print(f\"üîë API Key configured: {'Yes ‚úÖ' if API_KEY != 'your_api_key_here' else 'No ‚ùå - Please set OPENWEATHER_API_KEY'}\")\n",
    "print(f\"üîë API Key (masked): {API_KEY[:8]}...{API_KEY[-4:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ca873a",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. EXTRACT: Test API Connections\n",
    "\n",
    "### 2.1 Test One Call 3.0 API (Weather Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70212808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "\n",
      "‚úÖ One Call 3.0 API - SUCCESS!\n"
     ]
    }
   ],
   "source": [
    "# One Call 3.0 API - Current Weather\n",
    "ONECALL_URL = \"https://api.openweathermap.org/data/3.0/onecall\"\n",
    "\n",
    "def test_onecall_current():\n",
    "    \"\"\"Test One Call 3.0 API for current weather data.\"\"\"\n",
    "    params = {\n",
    "        'lat': LAT,\n",
    "        'lon': LON,\n",
    "        'appid': API_KEY,\n",
    "        'units': 'metric',\n",
    "        'exclude': 'minutely,hourly,daily,alerts'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(ONECALL_URL, params=params, timeout=10)\n",
    "        print(f\"Status Code: {response.status_code}\")\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            print(\"\\n‚úÖ One Call 3.0 API - SUCCESS!\")\n",
    "            return data\n",
    "        else:\n",
    "            print(f\"\\n‚ùå Error: {response.json()}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Exception: {e}\")\n",
    "        return None\n",
    "\n",
    "weather_response = test_onecall_current()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32dae522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Weather Response Structure:\n",
      "{\n",
      "  \"lat\": 33.6844,\n",
      "  \"lon\": 73.0479,\n",
      "  \"timezone\": \"Asia/Karachi\",\n",
      "  \"timezone_offset\": 18000,\n",
      "  \"current\": {\n",
      "    \"dt\": 1768047440,\n",
      "    \"sunrise\": 1768011179,\n",
      "    \"sunset\": 1768047416,\n",
      "    \"temp\": 12.86,\n",
      "    \"feels_like\": 10.75,\n",
      "    \"pressure\": 1018,\n",
      "    \"humidity\": 21,\n",
      "    \"dew_point\": -7.93,\n",
      "    \"uvi\": 0,\n",
      "    \"clouds\": 0,\n",
      "    \"visibility\": 10000,\n",
      "    \"wind_speed\": 2.64,\n",
      "    \"wind_deg\": 292,\n",
      "    \"wind_gust\": 3.32,\n",
      "    \"weather\": [\n",
      "      {\n",
      "        \"id\": 800,\n",
      "        \"main\": \"Clear\",\n",
      "        \"description\": \"clear sky\",\n",
      "        \"icon\": \"01n\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Inspect weather response structure\n",
    "if weather_response:\n",
    "    print(\"üìä Weather Response Structure:\")\n",
    "    print(json.dumps(weather_response, indent=2))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No weather data to display. Check API key.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6382b4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üå§Ô∏è Extracted Weather Features:\n",
      "  unix_time: 1768047440\n",
      "  datetime: 2026-01-10 12:17:20\n",
      "  temp: 12.86\n",
      "  feels_like: 10.75\n",
      "  humidity: 21\n",
      "  pressure: 1018\n",
      "  wind_speed: 2.64\n",
      "  wind_deg: 292\n",
      "  clouds: 0\n",
      "  visibility: 10000\n",
      "  dew_point: -7.93\n",
      "  uvi: 0\n"
     ]
    }
   ],
   "source": [
    "# Extract weather features from response\n",
    "def parse_weather_current(data):\n",
    "    \"\"\"Parse current weather data from One Call 3.0 API.\"\"\"\n",
    "    if not data or 'current' not in data:\n",
    "        return None\n",
    "    \n",
    "    current = data['current']\n",
    "    \n",
    "    weather_features = {\n",
    "        'unix_time': current.get('dt'),\n",
    "        'datetime': datetime.utcfromtimestamp(current.get('dt')),\n",
    "        'temp': current.get('temp'),\n",
    "        'feels_like': current.get('feels_like'),\n",
    "        'humidity': current.get('humidity'),\n",
    "        'pressure': current.get('pressure'),\n",
    "        'wind_speed': current.get('wind_speed'),\n",
    "        'wind_deg': current.get('wind_deg'),\n",
    "        'clouds': current.get('clouds'),\n",
    "        'visibility': current.get('visibility'),\n",
    "        'dew_point': current.get('dew_point'),\n",
    "        'uvi': current.get('uvi'),\n",
    "    }\n",
    "    \n",
    "    return weather_features\n",
    "\n",
    "if weather_response:\n",
    "    weather_features = parse_weather_current(weather_response)\n",
    "    print(\"üå§Ô∏è Extracted Weather Features:\")\n",
    "    for key, value in weather_features.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28978bbc",
   "metadata": {},
   "source": [
    "### 2.2 Test Air Pollution API (Pollutant Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b1c315b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "\n",
      "‚úÖ Air Pollution API - SUCCESS!\n"
     ]
    }
   ],
   "source": [
    "# Air Pollution API - Current\n",
    "POLLUTION_URL = \"http://api.openweathermap.org/data/2.5/air_pollution\"\n",
    "\n",
    "def test_pollution_current():\n",
    "    \"\"\"Test Air Pollution API for current pollution data.\"\"\"\n",
    "    params = {\n",
    "        'lat': LAT,\n",
    "        'lon': LON,\n",
    "        'appid': API_KEY\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(POLLUTION_URL, params=params, timeout=10)\n",
    "        print(f\"Status Code: {response.status_code}\")\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            print(\"\\n‚úÖ Air Pollution API - SUCCESS!\")\n",
    "            return data\n",
    "        else:\n",
    "            print(f\"\\n‚ùå Error: {response.json()}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Exception: {e}\")\n",
    "        return None\n",
    "\n",
    "pollution_response = test_pollution_current()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c05058af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Pollution Response Structure:\n",
      "{\n",
      "  \"coord\": {\n",
      "    \"lon\": 73.0479,\n",
      "    \"lat\": 33.6844\n",
      "  },\n",
      "  \"list\": [\n",
      "    {\n",
      "      \"main\": {\n",
      "        \"aqi\": 5\n",
      "      },\n",
      "      \"components\": {\n",
      "        \"co\": 1474.22,\n",
      "        \"no\": 0.09,\n",
      "        \"no2\": 13.21,\n",
      "        \"o3\": 132.26,\n",
      "        \"so2\": 4.1,\n",
      "        \"pm2_5\": 255.13,\n",
      "        \"pm10\": 326.34,\n",
      "        \"nh3\": 18.19\n",
      "      },\n",
      "      \"dt\": 1768047452\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Inspect pollution response structure\n",
    "if pollution_response:\n",
    "    print(\"üìä Pollution Response Structure:\")\n",
    "    print(json.dumps(pollution_response, indent=2))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No pollution data to display. Check API key.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc89a176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè≠ Extracted Pollution Features:\n",
      "  unix_time: 1768047452\n",
      "  datetime: 2026-01-10 12:17:32\n",
      "  aqi: 5\n",
      "  pm2_5: 255.13\n",
      "  pm10: 326.34\n",
      "  no2: 13.21\n",
      "  so2: 4.1\n",
      "  co: 1474.22\n",
      "  o3: 132.26\n",
      "  nh3: 18.19\n",
      "  no: 0.09\n"
     ]
    }
   ],
   "source": [
    "# Extract pollution features from response\n",
    "def parse_pollution_current(data):\n",
    "    \"\"\"Parse current pollution data from Air Pollution API.\"\"\"\n",
    "    if not data or 'list' not in data or len(data['list']) == 0:\n",
    "        return None\n",
    "    \n",
    "    item = data['list'][0]\n",
    "    components = item.get('components', {})\n",
    "    main = item.get('main', {})\n",
    "    \n",
    "    pollution_features = {\n",
    "        'unix_time': item.get('dt'),\n",
    "        'datetime': datetime.utcfromtimestamp(item.get('dt')),\n",
    "        'aqi': main.get('aqi'),  # 1-5 scale\n",
    "        'pm2_5': components.get('pm2_5'),\n",
    "        'pm10': components.get('pm10'),\n",
    "        'no2': components.get('no2'),\n",
    "        'so2': components.get('so2'),\n",
    "        'co': components.get('co'),\n",
    "        'o3': components.get('o3'),\n",
    "        'nh3': components.get('nh3'),\n",
    "        'no': components.get('no'),\n",
    "    }\n",
    "    \n",
    "    return pollution_features\n",
    "\n",
    "if pollution_response:\n",
    "    pollution_features = parse_pollution_current(pollution_response)\n",
    "    print(\"üè≠ Extracted Pollution Features:\")\n",
    "    for key, value in pollution_features.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fe2f5d",
   "metadata": {},
   "source": [
    "### 2.3 Test Historical Data APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d9c6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Call 3.0 Time Machine API - Historical Weather\n",
    "TIMEMACHINE_URL = \"https://api.openweathermap.org/data/3.0/onecall/timemachine\"\n",
    "\n",
    "def fetch_historical_weather(target_date):\n",
    "    \"\"\"Fetch historical weather data for a specific date.\"\"\"\n",
    "    unix_ts = int(target_date.timestamp())\n",
    "    \n",
    "    params = {\n",
    "        'lat': LAT,\n",
    "        'lon': LON,\n",
    "        'dt': unix_ts,\n",
    "        'appid': API_KEY,\n",
    "        'units': 'metric'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(TIMEMACHINE_URL, params=params, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"‚ùå Error: {response.status_code} - {response.text}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Exception: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test with yesterday's date\n",
    "yesterday = datetime.now() - timedelta(days=1)\n",
    "print(f\"üìÖ Fetching historical weather for: {yesterday.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "hist_weather = fetch_historical_weather(yesterday)\n",
    "if hist_weather:\n",
    "    print(\"‚úÖ Historical weather data fetched successfully!\")\n",
    "    print(f\"\\nData keys: {hist_weather.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7671dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Air Pollution History API\n",
    "POLLUTION_HISTORY_URL = \"http://api.openweathermap.org/data/2.5/air_pollution/history\"\n",
    "\n",
    "def fetch_historical_pollution(start_date, end_date):\n",
    "    \"\"\"Fetch historical pollution data for a date range.\"\"\"\n",
    "    start_unix = int(start_date.timestamp())\n",
    "    end_unix = int(end_date.timestamp())\n",
    "    \n",
    "    params = {\n",
    "        'lat': LAT,\n",
    "        'lon': LON,\n",
    "        'start': start_unix,\n",
    "        'end': end_unix,\n",
    "        'appid': API_KEY\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(POLLUTION_HISTORY_URL, params=params, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"‚ùå Error: {response.status_code} - {response.text}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Exception: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test with last 3 days\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=3)\n",
    "print(f\"üìÖ Fetching pollution history: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "hist_pollution = fetch_historical_pollution(start_date, end_date)\n",
    "if hist_pollution:\n",
    "    print(f\"‚úÖ Historical pollution data fetched successfully!\")\n",
    "    print(f\"üìä Number of records: {len(hist_pollution.get('list', []))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d1806a",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. TRANSFORM: Data Processing & Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53dc9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_historical_weather(data):\n",
    "    \"\"\"Parse historical weather data into a DataFrame.\"\"\"\n",
    "    if not data or 'data' not in data:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    records = []\n",
    "    for item in data['data']:\n",
    "        record = {\n",
    "            'unix_time': item.get('dt'),\n",
    "            'temp': item.get('temp'),\n",
    "            'feels_like': item.get('feels_like'),\n",
    "            'humidity': item.get('humidity'),\n",
    "            'pressure': item.get('pressure'),\n",
    "            'wind_speed': item.get('wind_speed'),\n",
    "            'wind_deg': item.get('wind_deg'),\n",
    "            'clouds': item.get('clouds'),\n",
    "            'visibility': item.get('visibility'),\n",
    "            'dew_point': item.get('dew_point'),\n",
    "            'uvi': item.get('uvi'),\n",
    "        }\n",
    "        records.append(record)\n",
    "    \n",
    "    df = pd.DataFrame(records)\n",
    "    if not df.empty:\n",
    "        df['datetime'] = pd.to_datetime(df['unix_time'], unit='s')\n",
    "        # Round to nearest hour for merging\n",
    "        df['hour_ts'] = (df['unix_time'] // 3600) * 3600\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Parse historical weather\n",
    "if hist_weather:\n",
    "    weather_df = parse_historical_weather(hist_weather)\n",
    "    print(f\"üå§Ô∏è Weather DataFrame Shape: {weather_df.shape}\")\n",
    "    display(weather_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f46206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_historical_pollution(data):\n",
    "    \"\"\"Parse historical pollution data into a DataFrame.\"\"\"\n",
    "    if not data or 'list' not in data:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    records = []\n",
    "    for item in data['list']:\n",
    "        components = item.get('components', {})\n",
    "        main = item.get('main', {})\n",
    "        \n",
    "        record = {\n",
    "            'unix_time': item.get('dt'),\n",
    "            'aqi': main.get('aqi'),\n",
    "            'pm2_5': components.get('pm2_5'),\n",
    "            'pm10': components.get('pm10'),\n",
    "            'no2': components.get('no2'),\n",
    "            'so2': components.get('so2'),\n",
    "            'co': components.get('co'),\n",
    "            'o3': components.get('o3'),\n",
    "            'nh3': components.get('nh3'),\n",
    "            'no': components.get('no'),\n",
    "        }\n",
    "        records.append(record)\n",
    "    \n",
    "    df = pd.DataFrame(records)\n",
    "    if not df.empty:\n",
    "        df['datetime'] = pd.to_datetime(df['unix_time'], unit='s')\n",
    "        # Round to nearest hour for merging\n",
    "        df['hour_ts'] = (df['unix_time'] // 3600) * 3600\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Parse historical pollution\n",
    "if hist_pollution:\n",
    "    pollution_df = parse_historical_pollution(hist_pollution)\n",
    "    print(f\"üè≠ Pollution DataFrame Shape: {pollution_df.shape}\")\n",
    "    display(pollution_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38131d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_weather_pollution(weather_df, pollution_df):\n",
    "    \"\"\"\n",
    "    Merge weather and pollution data by hour timestamp.\n",
    "    This creates the complete feature set for ML training.\n",
    "    \"\"\"\n",
    "    if weather_df.empty or pollution_df.empty:\n",
    "        print(\"‚ö†Ô∏è One or both DataFrames are empty!\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Merge on hour_ts\n",
    "    merged_df = pd.merge(\n",
    "        weather_df,\n",
    "        pollution_df,\n",
    "        on='hour_ts',\n",
    "        how='inner',\n",
    "        suffixes=('_weather', '_pollution')\n",
    "    )\n",
    "    \n",
    "    # Clean up duplicate columns\n",
    "    if 'unix_time_weather' in merged_df.columns:\n",
    "        merged_df['unix_time'] = merged_df['unix_time_weather']\n",
    "        merged_df = merged_df.drop(['unix_time_weather', 'unix_time_pollution'], axis=1, errors='ignore')\n",
    "    \n",
    "    if 'datetime_weather' in merged_df.columns:\n",
    "        merged_df['datetime'] = merged_df['datetime_weather']\n",
    "        merged_df = merged_df.drop(['datetime_weather', 'datetime_pollution'], axis=1, errors='ignore')\n",
    "    \n",
    "    # Reorder columns\n",
    "    cols_order = ['datetime', 'unix_time', 'hour_ts', \n",
    "                  'temp', 'feels_like', 'humidity', 'pressure', 'wind_speed', 'wind_deg',\n",
    "                  'clouds', 'visibility', 'dew_point', 'uvi',\n",
    "                  'aqi', 'pm2_5', 'pm10', 'no2', 'so2', 'co', 'o3', 'nh3', 'no']\n",
    "    \n",
    "    cols_present = [c for c in cols_order if c in merged_df.columns]\n",
    "    merged_df = merged_df[cols_present]\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "print(\"üîó This function will be used once we have matching data from both APIs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577c2bd3",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Complete ETL Pipeline Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d729bfeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Uncomment the line above to run the full ETL pipeline\n"
     ]
    }
   ],
   "source": [
    "def fetch_and_merge_data(num_days=7):\n",
    "    \"\"\"\n",
    "    Complete ETL pipeline to fetch and merge weather + pollution data.\n",
    "    \n",
    "    Args:\n",
    "        num_days: Number of historical days to fetch\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with merged weather and pollution features\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üöÄ Starting ETL Pipeline for {num_days} days\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    all_weather = []\n",
    "    all_pollution = []\n",
    "    \n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=num_days)\n",
    "    \n",
    "    # Step 1: Fetch Weather Data (day by day for Time Machine API)\n",
    "    print(\"üì° Step 1: Extracting Weather Data...\")\n",
    "    for day_offset in range(num_days):\n",
    "        target_date = end_date - timedelta(days=day_offset+1)\n",
    "        print(f\"  Fetching weather for {target_date.strftime('%Y-%m-%d')}...\", end=\" \")\n",
    "        \n",
    "        weather_data = fetch_historical_weather(target_date)\n",
    "        if weather_data:\n",
    "            df = parse_historical_weather(weather_data)\n",
    "            if not df.empty:\n",
    "                all_weather.append(df)\n",
    "                print(f\"‚úÖ ({len(df)} records)\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è No data\")\n",
    "        else:\n",
    "            print(\"‚ùå Failed\")\n",
    "        \n",
    "        time.sleep(0.5)  # Rate limiting\n",
    "    \n",
    "    # Step 2: Fetch Pollution Data (range query)\n",
    "    print(f\"\\nüì° Step 2: Extracting Pollution Data...\")\n",
    "    pollution_data = fetch_historical_pollution(start_date, end_date)\n",
    "    if pollution_data:\n",
    "        pollution_df = parse_historical_pollution(pollution_data)\n",
    "        if not pollution_df.empty:\n",
    "            print(f\"  ‚úÖ Pollution data: {len(pollution_df)} records\")\n",
    "            all_pollution.append(pollution_df)\n",
    "    \n",
    "    # Step 3: Combine and Merge\n",
    "    print(f\"\\nüîß Step 3: Transforming & Merging Data...\")\n",
    "    \n",
    "    if all_weather:\n",
    "        weather_df = pd.concat(all_weather, ignore_index=True)\n",
    "        print(f\"  Weather records: {len(weather_df)}\")\n",
    "    else:\n",
    "        weather_df = pd.DataFrame()\n",
    "        print(\"  ‚ö†Ô∏è No weather data collected\")\n",
    "    \n",
    "    if all_pollution:\n",
    "        pollution_df = pd.concat(all_pollution, ignore_index=True)\n",
    "        print(f\"  Pollution records: {len(pollution_df)}\")\n",
    "    else:\n",
    "        pollution_df = pd.DataFrame()\n",
    "        print(\"  ‚ö†Ô∏è No pollution data collected\")\n",
    "    \n",
    "    # Merge\n",
    "    if not weather_df.empty and not pollution_df.empty:\n",
    "        merged_df = merge_weather_pollution(weather_df, pollution_df)\n",
    "        print(f\"  ‚úÖ Merged records: {len(merged_df)}\")\n",
    "    else:\n",
    "        merged_df = pd.DataFrame()\n",
    "        print(\"  ‚ùå Cannot merge - missing data\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"‚úÖ ETL Pipeline Complete!\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "# Run the pipeline (use small number for testing)\n",
    "# merged_data = fetch_and_merge_data(num_days=3)\n",
    "print(\"‚ö†Ô∏è Uncomment the line above to run the full ETL pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b5e0ea",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a268990e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Run the ETL pipeline first, then call data_quality_report()\n"
     ]
    }
   ],
   "source": [
    "def data_quality_report(df, name=\"Dataset\"):\n",
    "    \"\"\"\n",
    "    Generate a data quality report for a DataFrame.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üìä Data Quality Report: {name}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    print(f\"üìè Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "    print(f\"\\nüìã Column Types:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    print(f\"\\nüîç Missing Values:\")\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = (missing / len(df) * 100).round(2)\n",
    "    missing_report = pd.DataFrame({\n",
    "        'Missing': missing,\n",
    "        'Percentage': missing_pct\n",
    "    })\n",
    "    print(missing_report[missing_report['Missing'] > 0])\n",
    "    \n",
    "    print(f\"\\nüìà Numeric Statistics:\")\n",
    "    display(df.describe())\n",
    "    \n",
    "    return missing_report\n",
    "\n",
    "# Example usage (will work once we have data)\n",
    "# quality_report = data_quality_report(merged_data, \"Merged AQI Data\")\n",
    "print(\"‚ö†Ô∏è Run the ETL pipeline first, then call data_quality_report()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c04e176",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d9b585c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Run the ETL pipeline first, then call visualize_aqi_data()\n"
     ]
    }
   ],
   "source": [
    "def visualize_aqi_data(df):\n",
    "    \"\"\"\n",
    "    Create visualizations for AQI data.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        print(\"‚ö†Ô∏è No data to visualize\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # 1. PM2.5 over time\n",
    "    if 'pm2_5' in df.columns and 'datetime' in df.columns:\n",
    "        axes[0, 0].plot(df['datetime'], df['pm2_5'], color='red', alpha=0.7)\n",
    "        axes[0, 0].set_title('PM2.5 Concentration Over Time')\n",
    "        axes[0, 0].set_xlabel('Date')\n",
    "        axes[0, 0].set_ylabel('PM2.5 (Œºg/m¬≥)')\n",
    "        axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 2. Temperature vs PM2.5\n",
    "    if 'temp' in df.columns and 'pm2_5' in df.columns:\n",
    "        axes[0, 1].scatter(df['temp'], df['pm2_5'], alpha=0.5, c='blue')\n",
    "        axes[0, 1].set_title('Temperature vs PM2.5')\n",
    "        axes[0, 1].set_xlabel('Temperature (¬∞C)')\n",
    "        axes[0, 1].set_ylabel('PM2.5 (Œºg/m¬≥)')\n",
    "    \n",
    "    # 3. Pollutant distribution\n",
    "    pollutants = ['pm2_5', 'pm10', 'no2', 'o3']\n",
    "    pollutants_present = [p for p in pollutants if p in df.columns]\n",
    "    if pollutants_present:\n",
    "        df[pollutants_present].boxplot(ax=axes[1, 0])\n",
    "        axes[1, 0].set_title('Pollutant Distributions')\n",
    "        axes[1, 0].set_ylabel('Concentration')\n",
    "    \n",
    "    # 4. Correlation heatmap\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 1:\n",
    "        corr_matrix = df[numeric_cols].corr()\n",
    "        sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', ax=axes[1, 1])\n",
    "        axes[1, 1].set_title('Feature Correlation Matrix')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "# visualize_aqi_data(merged_data)\n",
    "print(\"‚ö†Ô∏è Run the ETL pipeline first, then call visualize_aqi_data()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec63916",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. LOAD: Save Data to Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8567fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_local(df, filename=\"aqi_data.csv\"):\n",
    "    \"\"\"\n",
    "    Save DataFrame to local storage.\n",
    "    \"\"\"\n",
    "    output_path = f\"../data/raw/{filename}\"\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"‚úÖ Data saved to: {output_path}\")\n",
    "    print(f\"üìä Shape: {df.shape}\")\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "# Example usage\n",
    "# save_to_local(merged_data, \"aqi_training_data.csv\")\n",
    "print(\"‚ö†Ô∏è Run the ETL pipeline first, then save the data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48b8e94",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Quick Test (Minimal API Calls)\n",
    "\n",
    "Run this section to test the APIs with minimal calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda644af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_api_test():\n",
    "    \"\"\"\n",
    "    Quick test to verify both APIs are working.\n",
    "    Makes only 2 API calls (1 per API).\n",
    "    \"\"\"\n",
    "    print(\"üß™ Quick API Test\\n\")\n",
    "    \n",
    "    results = {\n",
    "        'one_call_api': False,\n",
    "        'pollution_api': False\n",
    "    }\n",
    "    \n",
    "    # Test 1: One Call 3.0 API\n",
    "    print(\"1Ô∏è‚É£ Testing One Call 3.0 API...\", end=\" \")\n",
    "    weather = test_onecall_current()\n",
    "    if weather and 'current' in weather:\n",
    "        results['one_call_api'] = True\n",
    "        temp = weather['current'].get('temp', 'N/A')\n",
    "        print(f\"   ‚Üí Current temp: {temp}¬∞C\")\n",
    "    \n",
    "    # Test 2: Air Pollution API  \n",
    "    print(\"\\n2Ô∏è‚É£ Testing Air Pollution API...\", end=\" \")\n",
    "    pollution = test_pollution_current()\n",
    "    if pollution and 'list' in pollution:\n",
    "        results['pollution_api'] = True\n",
    "        pm25 = pollution['list'][0]['components'].get('pm2_5', 'N/A')\n",
    "        print(f\"   ‚Üí Current PM2.5: {pm25} Œºg/m¬≥\")\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(\"üìã Test Results:\")\n",
    "    print(f\"   One Call 3.0 API: {'‚úÖ Working' if results['one_call_api'] else '‚ùå Failed'}\")\n",
    "    print(f\"   Air Pollution API: {'‚úÖ Working' if results['pollution_api'] else '‚ùå Failed'}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    if all(results.values()):\n",
    "        print(\"\\nüéâ All APIs working! Ready for full ETL pipeline.\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Some APIs failed. Check your API key and subscription.\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run quick test\n",
    "# api_results = quick_api_test()\n",
    "print(\"‚ö†Ô∏è Uncomment the line above to run the quick API test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b103c02",
   "metadata": {},
   "source": [
    "---\n",
    "## üìå Summary\n",
    "\n",
    "This notebook demonstrates the complete ETL pipeline for the Pearls AQI Predictor:\n",
    "\n",
    "| Step | Description | Status |\n",
    "|------|-------------|--------|\n",
    "| **Extract** | Fetch data from One Call 3.0 & Air Pollution APIs | ‚úÖ Implemented |\n",
    "| **Transform** | Parse, clean, and merge data by timestamp | ‚úÖ Implemented |\n",
    "| **Load** | Save to local CSV (Feature Store ready) | ‚úÖ Implemented |\n",
    "\n",
    "### Next Steps:\n",
    "1. Set your `OPENWEATHER_API_KEY` in `.env` file\n",
    "2. Run `quick_api_test()` to verify API connectivity\n",
    "3. Run `fetch_and_merge_data()` to collect training data\n",
    "4. Run `data_quality_report()` to validate data\n",
    "5. Proceed to feature engineering notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
